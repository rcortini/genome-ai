{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruggero_detector as rd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import multiply, Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-02-15 Multiple Ruggero detector\n",
    "I want to build a Ruggero detector in the case where there are multiple categories.\n",
    "\n",
    "We need to prepare the data differently now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(sentence_length, ntrain, nvalid, ntest, alpha_to_n, easter_eggs, noise=None) :\n",
    "    \n",
    "    # get data on the data set to build\n",
    "    N = ntrain + nvalid + ntest\n",
    "    n = len(easter_eggs)\n",
    "    \n",
    "    # build the sentences\n",
    "    sentences = []\n",
    "    targets = []\n",
    "    for i, easter_egg in enumerate(easter_eggs) :\n",
    "        sentences.append(rd.generate_sentences(N, sentence_length, alpha_to_n,\n",
    "                                               easter_egg=easter_egg))\n",
    "        targets.append(i*np.ones(N, dtype=np.int32))\n",
    "        \n",
    "    # now stack everything and shuffle\n",
    "    data = np.vstack(tuple(sentences))\n",
    "    targets = np.concatenate(tuple(targets))\n",
    "    \n",
    "    # shuffle the data\n",
    "    data, targets = rd.shuffle_data(data, targets)\n",
    "    \n",
    "    # now we partition data and targets into train, valid, and test sets\n",
    "    train_data = data[ : n*ntrain, :]\n",
    "    train_targets = targets[ : n*ntrain]\n",
    "    valid_data = data[n*ntrain : n*(ntrain+nvalid), :]\n",
    "    valid_targets = targets[n*ntrain : n*(ntrain+nvalid)]\n",
    "    test_data = data[n*(ntrain+nvalid) : , :]\n",
    "    test_targets = targets[n*(ntrain+nvalid) : ]\n",
    "    \n",
    "    # one further step is required, then return\n",
    "    train_data = to_categorical(np.expand_dims(train_data, axis = 2))\n",
    "    valid_data = to_categorical(np.expand_dims(valid_data, axis = 2))\n",
    "    test_data = to_categorical(np.expand_dims(test_data, axis = 2))\n",
    "    return train_data, train_targets,\\\n",
    "           valid_data, valid_targets,\\\n",
    "           test_data, test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our data set\n",
    "easter_eggs = [None, 'ruggero', 'cortini']\n",
    "ntrain = 10000\n",
    "nvalid = 2000\n",
    "ntest = 2000\n",
    "sentence_length = 80\n",
    "train_data, train_targets,\\\n",
    "valid_data, valid_targets,\\\n",
    "test_data, test_targets = prepare_data(sentence_length, ntrain, nvalid, ntest,\n",
    "                                       rd.alpha_to_n, easter_eggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check that everything's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100) :\n",
    "    s = test_data[i].argmax(axis=1)\n",
    "    print(s)\n",
    "    print(rd.decode_sentence(s, n_to_alpha=rd.n_to_alpha))\n",
    "    print(test_targets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now let's build our AI, this time with several neurons in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# LSTM layer\n",
    "lstm_units = 32\n",
    "model.add(LSTM(lstm_units, return_sequences=False, input_shape=(None, rd.nletters)))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(len(easter_eggs), activation='softmax'))\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# define checkpointer and fit the model\n",
    "checkpointer = ModelCheckpoint(filepath='../data/multi-ruggero-detector.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(train_data, to_categorical(train_targets),\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(valid_data, to_categorical(valid_targets)),\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(test_data, to_categorical(test_targets),\n",
    "                            batch_size=32,\n",
    "                            verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so this is extremely accurate in distinguishing between the three categories. Let's have a look at the activations of the three output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_response(m, data) :\n",
    "    \"\"\"\n",
    "    Outputs the response of the network as a function of the position in the sentence.\n",
    "    To speed up things, it passes series of data points in parallel.\n",
    "    \"\"\"\n",
    "    # get info on the data that was passed\n",
    "    nsentences = data.shape[0]\n",
    "    sentence_length = data.shape[1]\n",
    "    ndims = m.output_shape[1]\n",
    "    N = sentence_length-1\n",
    "    \n",
    "    # init the output data structure\n",
    "    predictions = np.zeros((nsentences, N, ndims))\n",
    "    for i in range(1, sentence_length) :\n",
    "        batch = data[:, :i, :]\n",
    "        p = m.predict(batch)\n",
    "        predictions[:, i-1, :] = p\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions of the network as a function of the letters read\n",
    "predictions = network_response(model, test_data[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "plt.plot(range(1, sentence_length), predictions[i, :, 0], color='b', label='Neuron 0')\n",
    "plt.plot(range(1, sentence_length), predictions[i, :, 1], color='r', label='Neuron 1')\n",
    "plt.plot(range(1, sentence_length), predictions[i, :, 2], color='k', label='Neuron 2')\n",
    "\n",
    "sentence = rd.decode_sentence(test_data[i].argmax(axis=1), n_to_alpha=rd.n_to_alpha)\n",
    "plt.xticks(np.arange(1, sentence_length), sentence)\n",
    "\n",
    "plt.legend(loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, here the behaviour of the system is what we would expect. Let's try to see what is the result if both targets are in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = 'lkjdfnvkjsdnfvlruggerodlkjbnsdkjbnlsdjkgbnsidkbnsdcortiniodkfnvboslodnfoivnsidfvnisdfnvs'\n",
    "sentence_2 = 'lkjdfnvkjsdnfvlcortinidlkjbnsdkjbnlsdjkgbnsidkbnsdruggeroodkfnvboslodnfoivnsidfvnisdfnvs'\n",
    "encoding_1 = rd.encode_sentence(sentence_1, alpha_to_n=rd.alpha_to_n)\n",
    "encoding_2 = rd.encode_sentence(sentence_2, alpha_to_n=rd.alpha_to_n)\n",
    "encoding = np.array((to_categorical(encoding_1, num_classes=rd.nletters),\n",
    "                      to_categorical(encoding_2, num_classes=rd.nletters)))\n",
    "p = network_response(model, encoding)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15,6))\n",
    "axes[0].plot(range(1, len(sentence_1)), p[0, :, 0], color='b', label='Neuron 0')\n",
    "axes[0].plot(range(1, len(sentence_1)), p[0, :, 1], color='r', label='Neuron 1')\n",
    "axes[0].plot(range(1, len(sentence_1)), p[0, :, 2], color='k', label='Neuron 2')\n",
    "axes[0].set_xticks(np.arange(1, len(sentence_1)))\n",
    "axes[0].set_xticklabels(sentence_1)\n",
    "\n",
    "axes[1].plot(range(1, len(sentence_2)), p[1, :, 0], color='b', label='Neuron 0')\n",
    "axes[1].plot(range(1, len(sentence_2)), p[1, :, 1], color='r', label='Neuron 1')\n",
    "axes[1].plot(range(1, len(sentence_2)), p[1, :, 2], color='k', label='Neuron 2')\n",
    "axes[1].set_xticks(np.arange(1, len(sentence_2)))\n",
    "axes[1].set_xticklabels(sentence_2)\n",
    "\n",
    "plt.legend(loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here there is an asymmetry between the two cases. If 'ruggero' is before 'cortini', a successive 'cortini' cannot make the model change its mind. The opposite is true. I'll build another data set and try to figure out why this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our data set\n",
    "easter_eggs = [None, 'ruggero', 'cobbick']\n",
    "ntrain = 10000\n",
    "nvalid = 2000\n",
    "ntest = 2000\n",
    "sentence_length = 80\n",
    "train_data_2, train_targets_2,\\\n",
    "valid_data_2, valid_targets_2,\\\n",
    "test_data_2, test_targets_2 = prepare_data(sentence_length, ntrain, nvalid, ntest,\n",
    "                                       rd.alpha_to_n, easter_eggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "# LSTM layer\n",
    "lstm_units = 32\n",
    "model_2.add(LSTM(lstm_units, return_sequences=False, input_shape=(None, rd.nletters)))\n",
    "\n",
    "# output layer\n",
    "model_2.add(Dense(len(easter_eggs), activation='softmax'))\n",
    "\n",
    "# compile\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# define checkpointer and fit the model\n",
    "checkpointer = ModelCheckpoint(filepath='../data/multi-ruggero-detector-2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model_2.fit(train_data_2, to_categorical(train_targets_2),\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(valid_data_2, to_categorical(valid_targets_2)),\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_2.evaluate(test_data_2, to_categorical(test_targets_2),\n",
    "                            batch_size=32,\n",
    "                            verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = 'lkjdfnvkjsdnfvlruggerodlkjbnsdkjbnlsdjkgbnsidkbnsdcobbickodkfnvboslodnfoivnsidfvnisdfnvs'\n",
    "sentence_2 = 'lkjdfnvkjsdnfvlcobbickdlkjbnsdkjbnlsdjkgbnsidkbnsdruggeroodkfnvboslodnfoivnsidfvnisdfnvs'\n",
    "encoding_1 = rd.encode_sentence(sentence_1, alpha_to_n=rd.alpha_to_n)\n",
    "encoding_2 = rd.encode_sentence(sentence_2, alpha_to_n=rd.alpha_to_n)\n",
    "encoding = np.array((to_categorical(encoding_1, num_classes=rd.nletters),\n",
    "                      to_categorical(encoding_2, num_classes=rd.nletters)))\n",
    "p = network_response(model_2, encoding)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15,6))\n",
    "axes[0].plot(range(1, len(sentence_1)), p[0, :, 0], color='b', label='Neuron 0')\n",
    "axes[0].plot(range(1, len(sentence_1)), p[0, :, 1], color='r', label='Neuron 1')\n",
    "axes[0].plot(range(1, len(sentence_1)), p[0, :, 2], color='k', label='Neuron 2')\n",
    "axes[0].set_xticks(np.arange(1, len(sentence_1)))\n",
    "axes[0].set_xticklabels(sentence_1)\n",
    "\n",
    "axes[1].plot(range(1, len(sentence_2)), p[1, :, 0], color='b', label='Neuron 0')\n",
    "axes[1].plot(range(1, len(sentence_2)), p[1, :, 1], color='r', label='Neuron 1')\n",
    "axes[1].plot(range(1, len(sentence_2)), p[1, :, 2], color='k', label='Neuron 2')\n",
    "axes[1].set_xticks(np.arange(1, len(sentence_2)))\n",
    "axes[1].set_xticklabels(sentence_2)\n",
    "\n",
    "plt.legend(loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we know that some sequences behave differently than others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "vpython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
