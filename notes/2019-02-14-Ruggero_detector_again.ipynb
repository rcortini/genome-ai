{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruggero_detector as rd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import multiply, Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-02-14 Ruggero detector again\n",
    "Once we established that it's difficult to extract meaningful information from attention layers before or after LSTMs, one remaining question is how to extract some information from it at all. LSTM layers are made for processing data one element at a time. So maybe we can use this fact to build a Ruggero detector that outputs a probability of having read \"Ruggero\" at each letter passed to the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our data set\n",
    "ntrain = 10000\n",
    "nvalid = 2000\n",
    "ntest = 2000\n",
    "sentence_length = 80\n",
    "train_data, train_targets,\\\n",
    "valid_data, valid_targets,\\\n",
    "test_data, test_targets = rd.prepare_data(sentence_length, ntrain, nvalid, ntest, rd.alpha_to_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to categorical\n",
    "train_data_cat = to_categorical(train_data)\n",
    "valid_data_cat = to_categorical(valid_data)\n",
    "test_data_cat = to_categorical(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time I will try to build a Ruggero-detector that has only an LSTM and an output neuron. Let's see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# LSTM layer\n",
    "lstm_units = 32\n",
    "model.add(LSTM(lstm_units, return_sequences=False, input_shape=(None, rd.nletters)))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# define checkpointer and fit the model\n",
    "checkpointer = ModelCheckpoint(filepath='../data/ruggero-detector.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(train_data_cat, train_targets,\n",
    "          batch_size=32,\n",
    "          epochs=2,\n",
    "          validation_data=(valid_data_cat, valid_targets),\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is still very high. A key difference here is that I built the network *without specifying how long are the input sequences*. Therefore, now I can feed whatever I want to the network, and it will output the probability.\n",
    "\n",
    "To test what the network is now able to detect, I want to look at the prediction of the network as a function of where we are in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'nilniarnoianciasnggerosnmidnsiunesiukljnedlvkjnsldkjjertninenjiinruruldjfnblsnbitn'\n",
    "sentence_encoded = rd.encode_sentence(sentence, alpha_to_n=rd.alpha_to_n)\n",
    "test = to_categorical(sentence_encoded, num_classes=rd.nletters)\n",
    "\n",
    "# iterate\n",
    "ranges = range(2, len(sentence))\n",
    "N = len(ranges)\n",
    "predictions = np.zeros(N)\n",
    "for i in ranges:\n",
    "    predictions[i-2] = model.predict(np.expand_dims(test[:i, :], axis=0))\n",
    "    \n",
    "fig = plt.figure(figsize=(15,3))\n",
    "plt.plot(ranges, predictions)\n",
    "plt.xticks(np.arange(len(sentence)), sentence)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fantastic result. I wonder now if these results can improve even further if I provide noisy data as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our data set\n",
    "ntrain = 10000\n",
    "nvalid = 2000\n",
    "ntest = 2000\n",
    "sentence_length = 80\n",
    "noise=2.0\n",
    "train_noisy_data, train_noisy_targets,\\\n",
    "valid_noisy_data, valid_noisy_targets,\\\n",
    "test_noisy_data, test_noisy_targets =\\\n",
    "rd.prepare_data(sentence_length, ntrain, nvalid, ntest, rd.alpha_to_n, noise=noise)\n",
    "\n",
    "# convert to categorical\n",
    "train_noisy_data_cat = to_categorical(train_noisy_data)\n",
    "valid_noisy_data_cat = to_categorical(valid_noisy_data)\n",
    "test_noisy_data_cat = to_categorical(test_noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noisy = Sequential()\n",
    "\n",
    "# LSTM layer\n",
    "lstm_units = 32\n",
    "model_noisy.add(LSTM(lstm_units, return_sequences=False, input_shape=(None, rd.nletters)))\n",
    "\n",
    "# output layer\n",
    "model_noisy.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile\n",
    "model_noisy.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# define checkpointer and fit the model\n",
    "checkpointer = ModelCheckpoint(filepath='../data/ruggero-detector.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model_noisy.fit(train_noisy_data_cat, train_noisy_targets,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(valid_noisy_data_cat, valid_noisy_targets),\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_response(m, data) :\n",
    "    \"\"\"\n",
    "    Outputs the response of the network as a function of the position in the sentence.\n",
    "    To speed up things, it passes series of data points in parallel.\n",
    "    \"\"\"\n",
    "    # get info on the data that was passed\n",
    "    nsentences = data.shape[0]\n",
    "    sentence_length = data.shape[1]\n",
    "    N = sentence_length-1\n",
    "    \n",
    "    # init the output data structure\n",
    "    predictions = np.zeros((nsentences, N))\n",
    "    for i in range(1, sentence_length) :\n",
    "        batch = data[:, :i]\n",
    "        p = m.predict(batch)\n",
    "        predictions[:, i-1] = p.squeeze()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch_sentences(sentences, alpha_to_n) :\n",
    "    # prepare the output data structure\n",
    "    nletters = len(alpha_to_n)\n",
    "    nsentences = len(sentences)\n",
    "    sentence_length = len(sentences[0])\n",
    "    sentences_encoded = np.zeros((nsentences, sentence_length, nletters))\n",
    "    \n",
    "    # encode them\n",
    "    for i, sentence in enumerate(sentences) :\n",
    "        s = rd.encode_sentence(sentence, alpha_to_n=rd.alpha_to_n)\n",
    "        sentences_encoded[i,:,:] = to_categorical(s, num_classes=nletters)\n",
    "    \n",
    "    # and return\n",
    "    return sentences_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target sentences\n",
    "sentence_with_target = 'nilniarnoianciasnmidruggeronsiunesiukljnedlvkjnsldkjjertninenjiinldjfnblsnbitn'\n",
    "sentence_without_target = 'nilniarnoianciasnmidrqrotbnznsiunesukljnedlvkjnsldkjjertninenjiinldjfnblsnbitn'\n",
    "\n",
    "# get the network predictions for the two sentences\n",
    "sentences_encoded = encode_batch_sentences([sentence_without_target, sentence_with_target],\n",
    "                                           alpha_to_n=rd.alpha_to_n)\n",
    "predictions = network_response(model_noisy, sentences_encoded)\n",
    "\n",
    "# plot the network response in the two cases\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15,6))\n",
    "axes[0].plot(range(1, len(sentence_without_target)), predictions[0])\n",
    "axes[0].set_xticks(np.arange(len(sentence_without_target)))\n",
    "axes[0].set_xticklabels(sentence_without_target)\n",
    "axes[0].set_ylabel(\"Response\")\n",
    "\n",
    "axes[1].plot(range(1, len(sentence_with_target)), predictions[1])\n",
    "axes[1].set_xticks(np.arange(len(sentence_with_target)))\n",
    "axes[1].set_xticklabels(sentence_with_target)\n",
    "axes[1].set_ylabel(\"Response\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this finally works very well, showing that indeed the network responds clearly to the sequence that contains the target. It is important at this point to remind ourselves of the fact that the network never knew what the target was.\n",
    "\n",
    "The next step in this journey is to try to identify the target by the response of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.ediff1d(prediction_with_target), color='b', label='With target')\n",
    "plt.plot(np.ediff1d(prediction_without_target), color='r', label='Without target')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Position in sequence')\n",
    "plt.ylabel('Response differential')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from this plot that we can try to figure out something about the target by looking at the sequence that's around the peak of the response differential. Let's try to explore this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the (categorical) test data \n",
    "test_with_target = test_noisy_data_cat[test_noisy_targets==1]\n",
    "sentences_with_target = [rd.decode_sentence(s, n_to_alpha=rd.n_to_alpha)\n",
    "                        for s in test_noisy_data[test_noisy_targets==1].squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the letter-by-letter predictions of our model\n",
    "predictions = network_response(model_noisy, test_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see whether this is working or not\n",
    "nsentences, sentence_length, nletters = test_with_target.shape\n",
    "i = 8\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "plt.plot(range(1, sentence_length), predictions[i])\n",
    "plt.xticks(np.arange(1, sentence_length), sentences_with_target[i])\n",
    "plt.ylabel(\"Response\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdiff = np.diff(predictions, axis=1).argmax(axis=1)\n",
    "l = 5\n",
    "for i in range(100) :\n",
    "    if maxdiff[i]-l<0 :\n",
    "        m = 0\n",
    "    else :\n",
    "        m = maxdiff[i]-l\n",
    "    if maxdiff[i]+l>=sentence_length :\n",
    "        M = sentence_length\n",
    "    else :\n",
    "        M = maxdiff[i]+l\n",
    "    s = sentences_with_target[i][m:M]\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stuff here shows that in most of the cases we are able to see that the target is present in these substrings that we extracted.\n",
    "\n",
    "One other thing that I would like to investigate is whether with the same kind of strategy we can figure out something about multiple categories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "vpython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
